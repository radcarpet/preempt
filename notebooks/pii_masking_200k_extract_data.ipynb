{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd28f129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/a/n/anshumaan/anaconda3/envs/privacy_prompt_rewriting/lib/python3.11/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import asyncio\n",
    "from functools import wraps\n",
    "import openai\n",
    "from faker import Faker\n",
    "from scipy.stats import kruskal\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0, '/u/a/n/anshumaan/phd_work/privacy_prompt_rewriting/universal-ner')\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import json\n",
    "import ast\n",
    "import random\n",
    "random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c637b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle data for english, french and german\n",
    "# say 10k samples each.\n",
    "import re\n",
    "\n",
    "def remove_brackets(text):\n",
    "    return re.sub(r'[\\[\\]]', '', text)    \n",
    "\n",
    "def preprocess_sample(sample):\n",
    "    \"\"\"\n",
    "    Sample is a dict (json) object!\n",
    "    Entities: [Money, Name, Age, SSN, Credit Card Number, Zipcode, Date]\n",
    "    Negative sampling: Take 10k \n",
    "    \n",
    "    Preprocess all samples, sample by entity type. \n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        \"AMOUNT\": \"Money\",\n",
    "        \"FIRSTNAME\": \"Name\",\n",
    "        \"LASTNAME\": \"Name\",\n",
    "        \"MIDDLENAME\": \"Name\",\n",
    "        \"AGE\": \"Age\",\n",
    "        \"CREDITCARDNUMBER\": \"Credit Card Number\",\n",
    "        \"ZIPCODE\": \"Zipcode\",\n",
    "        \"DATE\": \"Date\",\n",
    "        \"SSN\": \"SSN\",\n",
    "    }\n",
    "    text = sample['unmasked_text']\n",
    "    privacy_mask = ast.literal_eval(sample['privacy_mask'])\n",
    "    temp_dict = dict()\n",
    "    for key in privacy_mask:\n",
    "        value = privacy_mask[key]\n",
    "        formatted_key = remove_brackets(key).split('_')[0]\n",
    "        if formatted_key in mapping:\n",
    "            formatted_key = mapping[formatted_key]\n",
    "            \n",
    "        if formatted_key not in temp_dict: temp_dict[formatted_key] = []\n",
    "\n",
    "        # Intervene for positive and negative samples.\n",
    "        if formatted_key in mapping.values():   \n",
    "            formatted_value = value\n",
    "            temp_dict[formatted_key].append(formatted_value)\n",
    "    \n",
    "    conversations = []\n",
    "    labels = list(temp_dict.keys())\n",
    "    \n",
    "    # Get the first label in with the text.\n",
    "    human_input = {\n",
    "        \"from\": \"human\",\n",
    "        \"value\": f\"Passage: {text}\\n\\nWhat describes {labels[0]}?\"\n",
    "    }\n",
    "    model_output = {\n",
    "        \"from\": \"gpt\",\n",
    "        \"value\": f\"{temp_dict[labels[0]]}\".replace(\"'\", \"\\\"\")\n",
    "    }\n",
    "    conversations.append(human_input)\n",
    "    conversations.append(model_output)\n",
    "    \n",
    "    # Get other labels in.\n",
    "    for label in labels[1:]:\n",
    "        human_input = {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": f\"What describes {label}?\",\n",
    "        }\n",
    "        model_output = {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": f\"{temp_dict[label]}\".replace(\"'\", \"\\\"\"),\n",
    "        }\n",
    "        conversations.append(human_input)\n",
    "        conversations.append(model_output)\n",
    "    \n",
    "    # Format for data pipeline.\n",
    "    sample_input = {\n",
    "        \"id\": \"\",\n",
    "        \"conversations\":conversations,\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "    \n",
    "    return sample_input\n",
    "\n",
    "def read_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31ed145d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590439a5d33e4c8b91fc168b39adbf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "25993 17508\n",
      "{'id': '', 'conversations': [{'from': 'human', 'value': 'Passage: Your proficiency in bankruptcy laws is required to understand the case related to multiple transactions from cards issued by visa and numbered 7023222885014211.\\n\\nWhat describes CREDITCARDISSUER?'}, {'from': 'gpt', 'value': '[]'}, {'from': 'human', 'value': 'What describes Credit Card Number?'}, {'from': 'gpt', 'value': '[\"7023222885014211\"]'}], 'labels': ['CREDITCARDISSUER', 'Credit Card Number']}\n",
      "{'id': '', 'conversations': [{'from': 'human', 'value': 'Passage: Cis female, proposal to modify administrative law affects Manager duties. Please analyse the potential consequences for those based in Metz Key.\\n\\nWhat describes GENDER?'}, {'from': 'gpt', 'value': '[]'}, {'from': 'human', 'value': 'What describes JOBTYPE?'}, {'from': 'gpt', 'value': '[]'}, {'from': 'human', 'value': 'What describes STREET?'}, {'from': 'gpt', 'value': '[]'}], 'labels': ['GENDER', 'JOBTYPE', 'STREET']}\n",
      "################################################## \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd44274acd46418d90682e2b2c3c0d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52817 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "31826 20991\n",
      "{'id': '', 'conversations': [{'from': 'human', 'value': 'Passage: In der Welt von Home Loan Account ist es wichtig, bestimmte Themen anzusprechen, wie zum Beispiel Sexualaufklärung. Es ist tatsächlich ein wichtiger Aspekt unserer Gesellschaft, insbesondere für Personen unter 80 years.\\n\\nWhat describes ACCOUNTNAME?'}, {'from': 'gpt', 'value': '[]'}, {'from': 'human', 'value': 'What describes Age?'}, {'from': 'gpt', 'value': '[\"80 years\"]'}], 'labels': ['ACCOUNTNAME', 'Age']}\n",
      "{'id': '', 'conversations': [{'from': 'human', 'value': 'Passage: Eine sichere Browserpraxis beinhaltet das Nicht-Teilen Ihrer Fahrzeuginformationen DQ03TER HAUY2GV62HF633528 online.\\n\\nWhat describes VEHICLEVRM?'}, {'from': 'gpt', 'value': '[]'}, {'from': 'human', 'value': 'What describes VEHICLEVIN?'}, {'from': 'gpt', 'value': '[]'}], 'labels': ['VEHICLEVRM', 'VEHICLEVIN']}\n",
      "################################################## \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9175d96aa0463a9871a892bda7f766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61958 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "37534 24424\n",
      "{'id': '', 'conversations': [{'from': 'human', 'value': \"Passage: Cher(e) Hunter Smith, veuillez mettre à jour vos coordonnées enregistrées sous Caterina43@gmail.com. À l'avenir, ce sera la principale voie de communication entre les parents et les enseignants.\\n\\nWhat describes Name?\"}, {'from': 'gpt', 'value': '[\"Hunter\", \"Smith\"]'}, {'from': 'human', 'value': 'What describes EMAIL?'}, {'from': 'gpt', 'value': '[]'}], 'labels': ['Name', 'EMAIL']}\n",
      "{'id': '', 'conversations': [{'from': 'human', 'value': \"Passage: Nous avons remarqué une activité suspecte dans le portail des étudiants en STIM provenant de l'IPV6 : 33fd:d95e:cfb5:6c9e:c3cd:acfe:f220:bebe avec l'agent utilisateur : Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; .NET CLR 3.7.54868.6). Si ce n'était pas vous, veuillez réinitialiser votre MOT DE PASSE : O7tr2MC1KcWF et nous en informer immédiatement.\\n\\nWhat describes IPV6?\"}, {'from': 'gpt', 'value': '[]'}, {'from': 'human', 'value': 'What describes USERAGENT?'}, {'from': 'gpt', 'value': '[]'}, {'from': 'human', 'value': 'What describes PASSWORD?'}, {'from': 'gpt', 'value': '[]'}], 'labels': ['IPV6', 'USERAGENT', 'PASSWORD']}\n",
      "################################################## \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdb062e6ab2443cac9bfa551a5bd34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f53c80fecf14df98694096591d3ec53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = [\n",
    "    \"english_pii_43k.jsonl\",\n",
    "    \"german_pii_52k.jsonl\",\n",
    "    \"french_pii_62k.jsonl\",\n",
    "]\n",
    "# Entities: [Money, Name, Age, SSN, Credit Card Number, Zipcode, Date]\n",
    "entities = [\n",
    "    \"Money\", \"Name\", \"Age\", \"SSN\", \"Credit Card Number\", \"Zipcode\", \"Date\",\n",
    "]\n",
    "train_set = []\n",
    "test_set = []\n",
    "for name in names:\n",
    "    processed = []\n",
    "    file_path = f\"/nobackup3/divyam/data/pii-masking-200k/{name}\"\n",
    "    content = read_jsonl(file_path)\n",
    "    random.shuffle(content)\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        for result in tqdm(\n",
    "            executor.map(preprocess_sample, content), total=len(content)\n",
    "        ):\n",
    "            processed.append(result)\n",
    "    \n",
    "    positive_samples = []\n",
    "    negative_samples = []\n",
    "    for sample in processed:\n",
    "        a = set(sample['labels'])\n",
    "        b = entities\n",
    "        if a.intersection(b): positive_samples.append(sample)\n",
    "        else: negative_samples.append(sample)\n",
    "    \n",
    "    print(\"#\"*50)\n",
    "    print(len(positive_samples), len(negative_samples))\n",
    "    print(positive_samples[-1])\n",
    "    print(negative_samples[-1])\n",
    "    print(\"#\"*50,'\\n')\n",
    "\n",
    "    def train_test_split(samples):\n",
    "        a = samples[:int(0.7*len(samples))]\n",
    "        b = samples[int(0.7*len(samples)):]\n",
    "        return a, b\n",
    "    \n",
    "    train_positive, test_positive = train_test_split(positive_samples)\n",
    "    train_negative, test_negative = train_test_split(negative_samples)\n",
    "    train_set.extend(train_positive + train_negative)\n",
    "    test_set.extend(test_positive + test_negative)\n",
    "    \n",
    "#     processed = positive_samples + negative_samples\n",
    "#     final_processed.extend(processed)\n",
    "    \n",
    "for i in tqdm(range(len(train_set)), total=len(train_set)):\n",
    "    train_set[i][\"id\"] = f\"{i}\"\n",
    "\n",
    "for i in tqdm(range(len(test_set)), total=len(test_set)):\n",
    "    test_set[i][\"id\"] = f\"{i}\"\n",
    "    \n",
    "with open('datasets/preempt/pii_masking_200k_en_fr_de_train.json', 'w') as fp:\n",
    "    json.dump(train_set, fp, indent=2)\n",
    "    \n",
    "with open('datasets/preempt/pii_masking_200k_en_fr_de_test.json', 'w') as fp:\n",
    "    json.dump(test_set, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e31348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
